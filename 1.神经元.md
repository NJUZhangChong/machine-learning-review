## Hebb法则

连接强度与输入输出的乘积成正比，显然经常出现的模式将增强神经元之间的连接

## MP神经元

![image-20200417190619066](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417190619066.png)

![image-20200417190746704](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417190746704.png)

MP神经元的局限：

1. 输入方面：线性求和（无法做到非线性求和）
2. 输出方面：单一输出值（无法输出脉冲序列）
3. 更新机制：时钟同步更新（无法应对随机异步更新）



## 激励函数

神经网络中激励函数的作用通俗上讲就是将多个线性输入转换为非线性的关系。如果不使用激励函数的话，神经网络的每层都只是做线性变换，即使是多层输入叠加后也还是线性变换。通过激励函数引入非线性因素后，使神经网络的表示能力更强了。

通过在神经网络中加入非线性激励函数后，神经网络就有可能学习到平滑的曲线来实现对非线性数据的处理了。

下图右侧上是Sigmoid函数，右侧下是其对应的导数

![image-20200417192116798](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417192116798.png)





值域受限的称为饱和型激励函数，值域不受限的称为非饱和型激励函数

非饱和型激励函数应用广泛

![image-20200417192506014](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417192506014.png)

![image-20200417192706546](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417192706546.png)

## 感知机（可解决线性可分的问题）

感知机最简单形式的前馈式人工神经网络，是一种二元线性分类器，使用特征向量作为输入，把矩阵上的输入x(实数值向量)映射到输出值f(x)上（一个二元的值）

向量可能有几个维度，要把它映射到二元的值上

![image-20200417200634436](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417200634436.png)

引入学习的概念：刚开始随意给w,通过输入输出值调整w

感知机是学一条函数，w构成的直线，恰好将x1,x2分开；给出一个样本，能否学出这样一个函数。学习结果不唯一，保证分类正确就可以

![image-20200417200933038](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417200933038.png)

![image-20200417200844145](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417200844145.png)

![image-20200417201751758](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417201751758.png)

![image-20200417203725709](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417203725709.png)

![image-20200417203746587](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417203746587.png)

## 决策边界

通过一条直线把4个点划分开来，这样的直线称为决策边界

![image-20200417204323633](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417204323633.png)

决策边界又名鉴别函数，因为反应在几何平面上就是两个变量的函数，从数学上要学这样一个函数。神经元学的是一个w, 输入x是向量，x和w矩阵的转置相乘，判断这个值是否大于等于0，感知机最简单的大于0是1，小于0是-1。学习的是w权值，**w在平面上反应为决策边界**。从代数角度，输入x和神经元的w转置的点乘被称为两个向量的内积。要去找一个权值矩阵w去跟x做点乘，并判断点乘结果。假设x1,x2点乘结果均为1，找的w转置对应物理解释。感知机复杂的点在于判断的可能有很多的点，另外点乘结果不一定是1，不是要找绝对的垂直线。但通过这个例子，可以理解几何上要表达的关系。![image-20200417205904407](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417205904407.png)

![image-20200417210011985](d:\Downloads\Tips for 2019 Autumn - 2020 Spring\Tips for 2019 Autumn - 2020 Spring\大三第三学期 & 大三第四学期\3.机器学习\image-20200417210011985.png)

感知机允许输出神经元是多个，形成多分类，这是感知机改进的地方

mp只允许输出一个神经元

## 感知机收敛理论

![image-20200417210615162](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417210615162.png)

证明：

![image-20200417211458831](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417211458831.png)

![image-20200417211531308](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417211531308.png)



## 异或问题

感知机模型属于单层神经网路，它不能解决一类非线性可分的问题，典型例子是异或。对于异或问题，在二维空间中没有可分离点的直线。

解决方案：

如果还想要用线性分类器处理异或，必须要提高维度，在高维上用线性解决，这种技巧叫核技巧，把数据从低维向高维去练习

![image-20200417212631954](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417212631954.png)

![image-20200417212754171](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417212754171.png)

## 感知机表达能力

n个输入点，加一个偏置，在n+1维空间内找一个最优的偏置w*,线性决策函数的值是什么，权值是什么。**单层感知机可以解广义布尔函数，两层可以解决所有布尔函数，把所有逻辑表达出来。**我们可以用神经元和感知机的方式来实现人的逻辑。

![image-20200417213056653](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200417213056653.png)

## 感知机不足

感知机学习要想收敛必须依赖于训练样例线性可分，w\*要存在，如果w*不存在，则收敛定理不成立。

对于不是线性可分的训练样例，要么升维要么分层，否则学出来的模型不准确

感知机学习方法只适用于单层网络